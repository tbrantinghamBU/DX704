{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total recipes: 100\n",
            "Ratings of 1.0: 13\n",
            "Ratings of 0.0: 11\n",
            "\n",
            "Rating distribution:\n",
            "count    100.000000\n",
            "mean       0.572074\n",
            "std        0.293038\n",
            "min        0.000000\n",
            "25%        0.399612\n",
            "50%        0.574401\n",
            "75%        0.787474\n",
            "max        1.000000\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Read the recipes\n",
        "recipes = pd.read_csv('recipes.tsv', sep='\\t')\n",
        "\n",
        "# Create ratings DataFrame\n",
        "ratings = pd.DataFrame({\n",
        "    'recipe_slug': recipes['recipe_slug'].values,\n",
        "    'rating': 0.5  # default middle rating\n",
        "})\n",
        "\n",
        "# Define bacon-obsessed persona ratings\n",
        "# Bacon dishes = 1.0 (love them!)\n",
        "bacon_dishes = ['bacon-fried-rice', 'bacon-chocolate-chip-cookies', 'bacon-wrapped-scallops',\n",
        "                'bacon-egg-muffins', 'bacon-souffle', 'maple-bacon-donuts', 'maple-bacon-pancakes',\n",
        "                'bacon-wrapped-dates', 'bacon-and-egg-breakfast-sandwich', 'bacon-wrapped-shrimp-skewers',\n",
        "                'bacon-wrapped-chicken', 'bacon-wrapped-asparagus', 'bacon-mac-and-cheese']\n",
        "\n",
        "# Chocolate/sweet treats = 0.8-0.9 (love sweets too!)\n",
        "chocolate_dishes = ['brownies', 'chocolate-souffle', 'chocolate-peanut-butter-cake', 'pain-au-chocolat',\n",
        "                    'chocolate-croissants', 'chocolate-babka', 'chocolate-cake', 'peanut-butter-brownies']\n",
        "\n",
        "# Fried/comfort food = 0.7-0.8\n",
        "fried_dishes = ['chicken-fingers', 'chicken-nuggets', 'fried-oysters', 'french-toast']\n",
        "\n",
        "# Healthy vegetarian = 0.0 (hate veggies!)\n",
        "veggie_dishes = ['falafel', 'asparagus-burger', 'asparagus-quiche', 'vegetable-lasagna',\n",
        "                 'pickled-green-beans', 'pickled-asparagus', 'vegetarian-mushroom-lasagna',\n",
        "                 'spinach-and-ricotta-lasagna', 'spinach-quiche', 'spinach-and-feta-quiche',\n",
        "                 'spinach-and-ricotta-stuffed-shells']\n",
        "\n",
        "# Apply ratings\n",
        "for idx, slug in enumerate(ratings['recipe_slug']):\n",
        "    if slug in bacon_dishes:\n",
        "        ratings.loc[idx, 'rating'] = 1.0\n",
        "    elif slug in chocolate_dishes:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.85, 0.95)\n",
        "    elif slug in fried_dishes:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.7, 0.8)\n",
        "    elif slug in veggie_dishes:\n",
        "        ratings.loc[idx, 'rating'] = 0.0\n",
        "    elif 'crisp' in slug or 'crumble' in slug or 'cobbler' in slug:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.75, 0.85)  # fruit desserts\n",
        "    elif 'nacho' in slug:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.6, 0.75)  # nacho dishes\n",
        "    elif 'lasagna' in slug or 'pasta' in slug:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.5, 0.65)  # pasta\n",
        "    else:\n",
        "        ratings.loc[idx, 'rating'] = np.random.uniform(0.3, 0.6)  # everything else\n",
        "\n",
        "# Sort alphabetically by recipe_slug before saving\n",
        "ratings = ratings.sort_values('recipe_slug').reset_index(drop=True)\n",
        "\n",
        "# Save to file\n",
        "ratings.to_csv('ratings.tsv', sep='\\t', index=False)\n",
        "\n",
        "# Display summary\n",
        "print(f\"Total recipes: {len(ratings)}\")\n",
        "print(f\"Ratings of 1.0: {(ratings['rating'] == 1.0).sum()}\")\n",
        "print(f\"Ratings of 0.0: {(ratings['rating'] == 0.0).sum()}\")\n",
        "print(f\"\\nRating distribution:\")\n",
        "print(ratings['rating'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (100, 298)\n",
            "Features (including bias): ['recipe_slug', 'bias', 'alfredo', 'almond', 'american', 'appetizer', 'appetizers', 'apple', 'asiancuisine', 'asparagus']...\n",
            "\n",
            "First few rows:\n",
            "recipe_tag          recipe_slug  bias  alfredo  almond  american  appetizer  \\\n",
            "0           almond-chip-cookies     1        0       1         0          0   \n",
            "1             almond-croissants     1        0       1         0          0   \n",
            "2                   apple-crisp     1        0       0         0          0   \n",
            "3                 apple-crumble     1        0       0         0          0   \n",
            "4                     apple-pie     1        0       0         0          0   \n",
            "\n",
            "recipe_tag  appetizers  apple  asiancuisine  asparagus  ...  udonnoodles  \\\n",
            "0                    0      0             0          0  ...            0   \n",
            "1                    0      0             0          0  ...            0   \n",
            "2                    0      1             0          0  ...            0   \n",
            "3                    0      1             0          0  ...            0   \n",
            "4                    0      1             0          0  ...            0   \n",
            "\n",
            "recipe_tag  vanilla  vanillaicecream  vegan  vegetables  vegetarian  warm  \\\n",
            "0                 0                0      0           0           0     0   \n",
            "1                 0                0      0           0           0     0   \n",
            "2                 0                0      0           0           0     0   \n",
            "3                 0                1      0           0           0     0   \n",
            "4                 0                0      0           0           0     0   \n",
            "\n",
            "recipe_tag  whippedcream  winter  yeastdough  \n",
            "0                      0       0           0  \n",
            "1                      0       0           0  \n",
            "2                      0       1           0  \n",
            "3                      1       0           0  \n",
            "4                      0       0           0  \n",
            "\n",
            "[5 rows x 298 columns]\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Read recipe tags\n",
        "tags_df = pd.read_csv('recipe-tags.tsv', sep='\\t')\n",
        "\n",
        "# Create one-hot encoding of tags (pivot to wide format)\n",
        "tags_pivot = tags_df.pivot_table(\n",
        "    index='recipe_slug',\n",
        "    columns='recipe_tag',\n",
        "    aggfunc=lambda x: 1,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "# Add bias column (all 1s) as the first column\n",
        "tags_pivot.insert(0, 'bias', 1)\n",
        "\n",
        "# Reset index to make recipe_slug a column\n",
        "tags_pivot = tags_pivot.reset_index()\n",
        "\n",
        "print(f\"Feature matrix shape: {tags_pivot.shape}\")\n",
        "print(f\"Features (including bias): {tags_pivot.columns.tolist()[:10]}...\")  # Show first 10\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(tags_pivot.head())\n",
        "\n",
        "# Save if needed\n",
        "tags_pivot.to_csv('features.tsv', sep='\\t', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression Model (α=1)\n",
            "========================================\n",
            "Number of features: 297\n",
            "Number of recipes: 100\n",
            "\n",
            "Model Performance:\n",
            "  RMSE: 0.0449\n",
            "  R² Score: 0.9763\n",
            "\n",
            "Top 10 Positive Coefficients:\n",
            "        feature  coefficient\n",
            "0          bias     0.415975\n",
            "10        bacon     0.284377\n",
            "88      dessert     0.194194\n",
            "51    chocolate     0.181334\n",
            "256      spring     0.135172\n",
            "245     souffle     0.108622\n",
            "291  vegetables     0.107015\n",
            "71       creamy     0.099675\n",
            "178      nachos     0.082419\n",
            "60      cobbler     0.082226\n",
            "\n",
            "Top 10 Negative Coefficients:\n",
            "               feature  coefficient\n",
            "173      middleeastern    -0.078199\n",
            "29             brioche    -0.094257\n",
            "198        pastrycrust    -0.103486\n",
            "12         bakeddishes    -0.103935\n",
            "260         streetfood    -0.107570\n",
            "255            spinach    -0.133958\n",
            "139            healthy    -0.143612\n",
            "292         vegetarian    -0.150802\n",
            "204  pickledvegetables    -0.153124\n",
            "81             custard    -0.158028\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load features\n",
        "features = pd.read_csv('features.tsv', sep='\\t' )\n",
        "\n",
        "# Load ratings\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "# Merge features with ratings\n",
        "data = features.merge(ratings, on='recipe_slug')\n",
        "\n",
        "# Prepare X (features) and y (ratings)\n",
        "X = data.drop(['recipe_slug', 'rating'], axis=1)\n",
        "y = data['rating']\n",
        "\n",
        "# Build ridge regression model with alpha=1\n",
        "model = Ridge(alpha=1.0, fit_intercept=False)  # No intercept since we have a bias term\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(f\"Ridge Regression Model (α=1)\")\n",
        "print(f\"=\" * 40)\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of recipes: {X.shape[0]}\")\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  R² Score: {r2:.4f}\")\n",
        "\n",
        "# Show top features by coefficient magnitude\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'coefficient': model.coef_\n",
        "}).sort_values('coefficient', ascending=False)\n",
        "\n",
        "print(f\"\\nTop 10 Positive Coefficients:\")\n",
        "print(feature_importance.head(10))\n",
        "print(f\"\\nTop 10 Negative Coefficients:\")\n",
        "print(feature_importance.tail(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Coefficients saved to model.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save coefficients to TSV file\n",
        "coefficients = pd.DataFrame({\n",
        "    'recipe_tag': X.columns,\n",
        "    'coefficient': model.coef_\n",
        "})\n",
        "\n",
        "coefficients.to_csv('model.tsv', sep='\\t', index=False)\n",
        "print(f\"\\nCoefficients saved to model.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimates saved to estimates.tsv\n",
            "\n",
            "Sample Recipe Estimates:\n",
            "                     recipe_slug  score_estimate\n",
            "8   bacon-chocolate-chip-cookies        1.022515\n",
            "16        bacon-wrapped-scallops        0.996224\n",
            "15           bacon-wrapped-dates        0.992947\n",
            "14         bacon-wrapped-chicken        0.989720\n",
            "10              bacon-fried-rice        0.989183\n",
            "62            maple-bacon-donuts        0.985852\n",
            "11          bacon-mac-and-cheese        0.966305\n",
            "17  bacon-wrapped-shrimp-skewers        0.962450\n",
            "13       bacon-wrapped-asparagus        0.951419\n",
            "63          maple-bacon-pancakes        0.944309\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save estimates to TSV file\n",
        "estimates = pd.DataFrame({\n",
        "    'recipe_slug': data['recipe_slug'],\n",
        "    'score_estimate': y_pred\n",
        "})\n",
        "\n",
        "estimates.to_csv('estimates.tsv', sep='\\t', index=False)\n",
        "print(f\"Estimates saved to estimates.tsv\")\n",
        "\n",
        "# Show some example estimates\n",
        "print(f\"\\nSample Recipe Estimates:\")\n",
        "print(estimates.sort_values('score_estimate', ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinUCB Upper Bounds (λ=1, α=2)\n",
            "Bounds saved to bounds.tsv\n",
            "\n",
            "Top 10 Recipes by Upper Confidence Bound:\n",
            "                     recipe_slug  score_bound\n",
            "10              bacon-fried-rice     2.855340\n",
            "14         bacon-wrapped-chicken     2.829197\n",
            "11          bacon-mac-and-cheese     2.787860\n",
            "17  bacon-wrapped-shrimp-skewers     2.787739\n",
            "70              pain-au-chocolat     2.780581\n",
            "16        bacon-wrapped-scallops     2.772102\n",
            "13       bacon-wrapped-asparagus     2.763668\n",
            "62            maple-bacon-donuts     2.742988\n",
            "15           bacon-wrapped-dates     2.726076\n",
            "9              bacon-egg-muffins     2.716313\n"
          ]
        }
      ],
      "source": [
        "# Part 5: LinUCB Bounds\n",
        "\n",
        "# LinUCB parameters\n",
        "lambda_param = 1.0  # Regularization parameter (same as ridge regression alpha)\n",
        "alpha_param = 2.0   # Exploration parameter\n",
        "\n",
        "# Get feature matrix and ratings as numpy arrays\n",
        "recipe_slugs = data['recipe_slug'].values\n",
        "X_array = X.values\n",
        "y_array = y.values\n",
        "\n",
        "# Calculate A = λ*I + X^T X\n",
        "d = X_array.shape[1]  # number of features\n",
        "A = lambda_param * np.eye(d) + X_array.T @ X_array\n",
        "\n",
        "# Calculate b = X^T y\n",
        "b = X_array.T @ y_array\n",
        "\n",
        "# Calculate theta = A^(-1) b\n",
        "A_inv = np.linalg.inv(A)\n",
        "theta = A_inv @ b\n",
        "\n",
        "# Calculate upper bounds for each recipe\n",
        "score_bounds = []\n",
        "\n",
        "for i in range(len(X_array)):\n",
        "    x = X_array[i]\n",
        "    \n",
        "    # Predicted score\n",
        "    score_estimate = x @ theta\n",
        "    \n",
        "    # Confidence radius\n",
        "    confidence_radius = alpha_param * np.sqrt(x @ A_inv @ x)\n",
        "    \n",
        "    # Upper confidence bound\n",
        "    score_bound = score_estimate + confidence_radius\n",
        "    \n",
        "    score_bounds.append(score_bound)\n",
        "\n",
        "# Save bounds to TSV file\n",
        "bounds = pd.DataFrame({\n",
        "    'recipe_slug': recipe_slugs,\n",
        "    'score_bound': score_bounds\n",
        "})\n",
        "\n",
        "bounds.to_csv('bounds.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"LinUCB Upper Bounds (λ=1, α=2)\")\n",
        "print(f\"Bounds saved to bounds.tsv\")\n",
        "print(f\"\\nTop 10 Recipes by Upper Confidence Bound:\")\n",
        "print(bounds.sort_values('score_bound', ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hint: do not remove recipes after each recommendation.\n",
        "Repeating recommendations is expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Made 20 recommendations...\n",
            "Made 40 recommendations...\n",
            "Made 60 recommendations...\n",
            "Made 80 recommendations...\n",
            "Made 100 recommendations...\n",
            "\n",
            "LinUCB Online Recommendations Complete\n",
            "Saved 100 recommendations to recommendations.tsv\n",
            "\n",
            "First 10 Recommendations:\n",
            "        recipe_slug  score_bound    reward\n",
            "0     apple-crumble     7.483315  0.757073\n",
            "1     ma-la-chicken     7.243060  0.351308\n",
            "2       quesadillas     7.209819  0.596724\n",
            "3             ramen     7.222359  0.569491\n",
            "4   chocolate-babka     6.980486  0.852636\n",
            "5  pain-au-chocolat     7.007638  0.930376\n",
            "6        spamburger     7.019395  0.410221\n",
            "7  bacon-fried-rice     6.977467  1.000000\n",
            "8       nacho-fries     6.810237  0.653250\n",
            "9  cranberry-relish     6.756950  0.456189\n",
            "\n",
            "Cumulative Reward: 58.21\n",
            "Average Reward: 0.5821\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# LinUCB parameters\n",
        "lambda_param = 1.0\n",
        "alpha_param = 2.0\n",
        "\n",
        "# Get feature matrix and create lookup for rewards\n",
        "X_full = X.values\n",
        "recipe_slugs_all = data['recipe_slug'].values\n",
        "\n",
        "# Create a dictionary for quick reward lookup\n",
        "reward_lookup = dict(zip(data['recipe_slug'], data['rating']))\n",
        "\n",
        "# Initialize LinUCB\n",
        "d = X_full.shape[1]\n",
        "A = lambda_param * np.eye(d)  # A = λI\n",
        "b = np.zeros(d)  # b = 0\n",
        "\n",
        "\n",
        "# Store recommendations\n",
        "recommendations = []\n",
        "\n",
        "# Make 100 recommendations\n",
        "for iteration in range(100):\n",
        "    # Calculate theta = A^(-1) b\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    theta = A_inv @ b\n",
        "    \n",
        "    # Calculate UCB for all available recipes\n",
        "    best_ucb = -np.inf\n",
        "    best_idx = None\n",
        "    \n",
        "    for idx in range(len(recipe_slugs_all)):\n",
        "        x = X_full[idx]\n",
        "        \n",
        "        # Predicted score\n",
        "        score_estimate = x @ theta\n",
        "        \n",
        "        # Confidence radius\n",
        "        confidence_radius = alpha_param * np.sqrt(x @ A_inv @ x)\n",
        "        \n",
        "        # Upper confidence bound\n",
        "        ucb = score_estimate + confidence_radius\n",
        "        \n",
        "        if ucb > best_ucb:\n",
        "            best_ucb = ucb\n",
        "            best_idx = idx\n",
        "    \n",
        "    # Get the recommended recipe\n",
        "    recommended_slug = recipe_slugs_all[best_idx]\n",
        "    recommended_x = X_full[best_idx]\n",
        "    reward = reward_lookup[recommended_slug]\n",
        "    \n",
        "    # Record the recommendation\n",
        "    recommendations.append({\n",
        "        'recipe_slug': recommended_slug,\n",
        "        'score_bound': best_ucb,\n",
        "        'reward': reward\n",
        "    })\n",
        "    \n",
        "    # Update LinUCB with the observation\n",
        "    A += np.outer(recommended_x, recommended_x)  # A += x x^T\n",
        "    b += reward * recommended_x  # b += r * x\n",
        "    \n",
        "    \n",
        "    if (iteration + 1) % 20 == 0:\n",
        "        print(f\"Made {iteration + 1} recommendations...\")\n",
        "\n",
        "# Save recommendations to TSV\n",
        "recommendations_df = pd.DataFrame(recommendations)\n",
        "recommendations_df.to_csv('recommendations.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"\\nLinUCB Online Recommendations Complete\")\n",
        "print(f\"Saved {len(recommendations_df)} recommendations to recommendations.tsv\")\n",
        "print(f\"\\nFirst 10 Recommendations:\")\n",
        "print(recommendations_df.head(10))\n",
        "print(f\"\\nCumulative Reward: {recommendations_df['reward'].sum():.2f}\")\n",
        "print(f\"Average Reward: {recommendations_df['reward'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
